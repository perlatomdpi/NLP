{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT vs Word2Vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNu8v0tLOtuxQfxz/lsSqSV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/perlatomdpi/NLP/blob/main/BERT_vs_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBYlmCoXTEhO"
      },
      "source": [
        "# **BERT vs Word2Vec**\n",
        "Here we calcualte the distance of the word apple in two different context.\n",
        "Word2Vec is not able to capture the context of the word.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVaWxcVFSwpp"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6l5a29QTZXG"
      },
      "source": [
        "import numpy as np\n",
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "from flair.data import Sentence\n",
        "from scipy.spatial import distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6F9mTsrTljI"
      },
      "source": [
        "# **Glove embedding**\n",
        "Word2Vec generates embeddings that are context independent.\n",
        "This means that the same word (e.g. apple) presented in different context has the same vector representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BClRr9n1TotO",
        "outputId": "792becc4-8fcc-4ccf-e782-46cc1719bf6c"
      },
      "source": [
        "glove_embedding = WordEmbeddings('glove')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-30 15:04:22,840 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmpttu4fy8l\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 160000128/160000128 [00:06<00:00, 24474053.80B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-30 15:04:29,712 copying /tmp/tmpttu4fy8l to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-30 15:04:29,965 removing temp file /tmp/tmpttu4fy8l\n",
            "2021-04-30 15:04:30,419 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmpv3bs44ul\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 21494764/21494764 [00:01<00:00, 14018897.93B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-30 15:04:32,286 copying /tmp/tmpv3bs44ul to cache at /root/.flair/embeddings/glove.gensim\n",
            "2021-04-30 15:04:32,316 removing temp file /tmp/tmpv3bs44ul\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2xLaEFcVQ75"
      },
      "source": [
        "# **Sentence 1**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_mt-cGdT3Tv"
      },
      "source": [
        "sentence_1 = Sentence('apple released iphone 12 pro max in 2020')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEgLnDvYVYFo",
        "outputId": "230a8ee7-0bf8-4a62-b13f-fc05d4ab3049"
      },
      "source": [
        "glove_embedding.embed(sentence_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence: \"apple released iphone 12 pro max in 2020\"   [− Tokens: 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bExxG3NuVYCw"
      },
      "source": [
        "# Per each token in the sentece show me the tensor representation\n",
        "for token in sentence_1:\n",
        "    print(token)\n",
        "    print(token.embedding)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDyz450VWbRT",
        "outputId": "6f76154a-6d60-41f3-876f-fcdbb18c145c"
      },
      "source": [
        "sentence_1[0].embedding # show the apple tensor ins sentence 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5985, -0.4632,  0.1300, -0.0196,  0.4603, -0.3018,  0.8977, -0.6563,\n",
              "         0.6686, -0.4916,  0.0376, -0.0509,  0.6451, -0.5388, -0.3765, -0.0431,\n",
              "         0.5138,  0.1778,  0.2860,  0.9206, -0.4935, -0.4858,  0.6132,  0.7821,\n",
              "         0.1925,  0.9123, -0.0556, -0.1251, -0.6569,  0.0686,  0.5563,  1.6110,\n",
              "        -0.0074, -0.4888,  0.4549,  0.9610, -0.0634,  0.1743,  0.9814, -1.3125,\n",
              "        -0.1580, -0.5430, -0.1389, -0.2615, -0.3691,  0.2684, -0.2438, -0.1948,\n",
              "         0.6258, -0.7377,  0.3835, -0.7500, -0.3905,  0.0915, -0.3659, -1.4715,\n",
              "        -0.4523,  0.2256,  1.1412, -0.3853, -0.0672,  0.5729, -0.3919,  0.3130,\n",
              "        -0.2923, -0.9616,  0.1515, -0.2166,  0.2510,  0.0970,  0.2843,  1.4296,\n",
              "        -0.5056, -0.5137, -0.4722,  0.3204,  0.0231,  0.2262, -0.0972,  0.8213,\n",
              "         0.9260, -1.0086, -0.3864,  0.8641, -1.2060, -0.2853,  0.2265, -0.3877,\n",
              "         0.4088,  0.5930,  0.3077,  0.8380, -0.6366, -0.4464, -0.4341, -0.7936,\n",
              "        -0.2867, -0.0344,  1.3431,  0.3490])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Q88PuivVrgy",
        "outputId": "866552a6-ba6f-4896-94a4-7d59b82641b4"
      },
      "source": [
        "sentence_1[0].embedding.shape # the token has size 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-1HceV5V3oE"
      },
      "source": [
        "# **Sentence 2**\n",
        "The word (token) \"apple\" here is mentioined in a different context than in Sentence 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS_mrq-FV5J3"
      },
      "source": [
        "sentence_2 = Sentence('an apple a day keeps the doctor away') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqBwz7ANWKXj",
        "outputId": "e1d47bf4-1381-42a0-8cf8-38a26191f776"
      },
      "source": [
        "glove_embedding.embed(sentence_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Sentence: \"an apple a day keeps the doctor away\"   [− Tokens: 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdt6PkYNWOK1"
      },
      "source": [
        "for token in sentence_2:\n",
        "    print(token)\n",
        "    print(token.embedding)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l1apC26WUVM",
        "outputId": "f81b3454-78ae-47de-8130-70e9adb3771e"
      },
      "source": [
        "sentence_2[1].embedding # show the apple tensor ins sentence 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5985, -0.4632,  0.1300, -0.0196,  0.4603, -0.3018,  0.8977, -0.6563,\n",
              "         0.6686, -0.4916,  0.0376, -0.0509,  0.6451, -0.5388, -0.3765, -0.0431,\n",
              "         0.5138,  0.1778,  0.2860,  0.9206, -0.4935, -0.4858,  0.6132,  0.7821,\n",
              "         0.1925,  0.9123, -0.0556, -0.1251, -0.6569,  0.0686,  0.5563,  1.6110,\n",
              "        -0.0074, -0.4888,  0.4549,  0.9610, -0.0634,  0.1743,  0.9814, -1.3125,\n",
              "        -0.1580, -0.5430, -0.1389, -0.2615, -0.3691,  0.2684, -0.2438, -0.1948,\n",
              "         0.6258, -0.7377,  0.3835, -0.7500, -0.3905,  0.0915, -0.3659, -1.4715,\n",
              "        -0.4523,  0.2256,  1.1412, -0.3853, -0.0672,  0.5729, -0.3919,  0.3130,\n",
              "        -0.2923, -0.9616,  0.1515, -0.2166,  0.2510,  0.0970,  0.2843,  1.4296,\n",
              "        -0.5056, -0.5137, -0.4722,  0.3204,  0.0231,  0.2262, -0.0972,  0.8213,\n",
              "         0.9260, -1.0086, -0.3864,  0.8641, -1.2060, -0.2853,  0.2265, -0.3877,\n",
              "         0.4088,  0.5930,  0.3077,  0.8380, -0.6366, -0.4464, -0.4341, -0.7936,\n",
              "        -0.2867, -0.0344,  1.3431,  0.3490])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jltr_MSiW1SC"
      },
      "source": [
        "As we can see fro the two tensors, the word \"apple\" has the same embedding evenif it's used in two very different context. Now we can calculate the distance between the two \"apple\" tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImCs5vJeXR6U"
      },
      "source": [
        "# **Glove distance bewteen the same word \"apple\" used in different contexts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrcXMoh8Wi_w"
      },
      "source": [
        "glove_dst = distance.euclidean(np.array(sentence_1[0].embedding), \n",
        "                               np.array(sentence_2[1].embedding))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbmTfk_DXity",
        "outputId": "27ebb2e7-620e-4222-df48-3e89ee647267"
      },
      "source": [
        "print(\"Distance between apple embeddings for Word2Vec = {}\".format(glove_dst))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance between apple embeddings for Word2Vec = 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulKigOEDXpnE"
      },
      "source": [
        "The Distance between apple embeddings = 0.0 conferms that word2vec is not able to take into account the context where the workds are used.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLdmnd4cYFni"
      },
      "source": [
        "# **BERT embeddings**\n",
        "Here the list of PreTrained BERT models: https://www.sbert.net/docs/pretrained_models.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjTYKnkIYLgF"
      },
      "source": [
        "# Download the model\n",
        "bert_embedding = TransformerWordEmbeddings('bert-base-multilingual-cased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhC5X-9TZFsg"
      },
      "source": [
        "# Get embedding of every workds in the sentence 1\n",
        "bert_embedding.embed(sentence_1)\n",
        "for token in sentence_1:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1AlUwxfZi8r",
        "outputId": "ef476175-eabb-47ee-e96f-5383d17f7b3a"
      },
      "source": [
        "# Showme embedding of word appple\n",
        "sentence_1[0].embedding\n",
        "\n",
        "# Show me the size of the word apple using BERT\n",
        "sentence_1[0].embedding.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([868])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlgjH8LRZ5bs"
      },
      "source": [
        "# Get embedding of every workds in the sentence 2\n",
        "bert_embedding.embed(sentence_2)\n",
        "\n",
        "for token in sentence_2:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emodUyryZ-kK"
      },
      "source": [
        "# **Calculate Distance of the two apple tokens using BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHRV_WTtaGpT"
      },
      "source": [
        "bert_dst = distance.euclidean(np.array(sentence_1[0].embedding), \n",
        "                               np.array(sentence_2[1].embedding))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_KShPpjaK7e",
        "outputId": "07486569-b6ea-43ef-a36b-4ef24990b772"
      },
      "source": [
        "print(\"Distance between apple embeddings for Word2Vec = {}\".format(glove_dst))\n",
        "print(\"Distance between apple embeddings for BERT = {}\".format(bert_dst))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance between apple embeddings for Word2Vec = 0.0\n",
            "Distance between apple embeddings for BERT = 11.68575382232666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HU309LVamEF"
      },
      "source": [
        "Here we can clearly see that BERT is able to capture the context of a word.\n",
        "BERT models are context dependents."
      ]
    }
  ]
}